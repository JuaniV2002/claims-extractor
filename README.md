# Proyecto Final - IA: Identificador de Marcas de Autos üöó

Sistema de IA que **aprende a identificar marcas** de autom√≥viles a partir de c√≥digos alfanum√©ricos inventados, demostrando **aprendizaje real** mediante few-shot learning con LLMs.

## üéØ Objetivo del Proyecto

Demostrar que un LLM puede **aprender informaci√≥n completamente nueva** (c√≥digos que nunca vio antes) usando t√©cnicas de:
- ‚úÖ Few-shot learning (ejemplos en el prompt)
- ‚úÖ System prompts configurados
- ‚úÖ Prompt engineering

## üìä Prueba de Aprendizaje Real

### ‚ùå Sin entrenamiento (modelo base):
```bash
echo "C√≥digo: TOY-2847A" | ollama run llama3.2
# Respuesta: "No puedo identificar el c√≥digo TOY-2847A..."
# Precisi√≥n: 0% ‚ùå
```

### ‚úÖ Con few-shot learning:
```bash
python3 training/few_shot_learning.py
# Precisi√≥n: 67% en c√≥digos del dataset ‚úÖ
# Precisi√≥n: 50% en c√≥digos nuevos (generalizaci√≥n) üéØ
```

**Esto demuestra APRENDIZAJE REAL** - el modelo aprende c√≥digos que nunca existieron en su entrenamiento original.

## üèóÔ∏è Estructura del Proyecto

```
car_ai/
‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_codes.jsonl         # Dataset con c√≥digos INVENTADOS
‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îú‚îÄ‚îÄ training_data_codes.jsonl   # Dataset convertido para Ollama
‚îÇ   ‚îú‚îÄ‚îÄ convert_dataset.py          # Convertir formato
‚îÇ   ‚îú‚îÄ‚îÄ few_shot_learning.py        # üéì APRENDIZAJE REAL con ejemplos
‚îÇ   ‚îú‚îÄ‚îÄ compare_models.py           # Comparaci√≥n antes/despu√©s
‚îÇ   ‚îú‚îÄ‚îÄ verify_base_model.py        # Verificar que c√≥digos son nuevos
‚îÇ   ‚îî‚îÄ‚îÄ test_model.py               # Tests del modelo
‚îú‚îÄ‚îÄ Modelfile_codes                 # Config para c√≥digos inventados
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Uso R√°pido

### Experimento 1: Verificar que el modelo NO conoce los c√≥digos
```bash
python3 training/verify_base_model.py
```

### Experimento 2: Comparar modelo base vs configurado
```bash
python3 training/compare_models.py
```

### Experimento 3: üéØ Few-Shot Learning (APRENDIZAJE REAL)
```bash
python3 training/few_shot_learning.py
```

Este √∫ltimo experimento demuestra que:
- ‚úÖ El modelo aprende c√≥digos completamente nuevos
- ‚úÖ Generaliza a c√≥digos no vistos (detecta patrones)
- ‚úÖ Mejora de 0% ‚Üí 67% de precisi√≥n

## üéØ Ejemplos de Uso

### Sistema de c√≥digos inventados (aprendizaje real):
```bash
# Verificar que el modelo base NO los conoce
echo "C√≥digo: TOY-2847A" | ollama run llama3.2
# ‚ùå "No puedo identificar este c√≥digo"

# Usar few-shot learning para ense√±arle
python3 training/few_shot_learning.py
# ‚úÖ Aprende que TOY-2847A ‚Üí Toyota
```

### Sistema tradicional (el modelo ya conoce las marcas):
```bash
ollama run car-brands
# Auto: Toyota Corolla ‚Üí Toyota ‚úÖ
# (Funciona pero no es aprendizaje nuevo)
```

## üìä Dataset

### Dataset 1: Marcas Reales (`dataset.jsonl`)
- **Total:** 100 ejemplos
- **Problema:** El modelo YA conoce estas marcas
- **Uso:** Baseline, no demuestra aprendizaje nuevo

### Dataset 2: C√≥digos Inventados (`dataset_codes.jsonl`) ‚≠ê
- **Total:** 100 ejemplos
- **C√≥digos:** TOY-2847A, FRD-4821X, VWG-3947K, etc.
- **Ventaja:** El modelo NUNCA vio estos c√≥digos
- **Uso:** Demuestra aprendizaje real

#### Formato de c√≥digos:
```
TOY-XXXX ‚Üí Toyota
FRD-XXXX ‚Üí Ford
VWG-XXXX ‚Üí Volkswagen
CHV-XXXX ‚Üí Chevrolet
RNT-XXXX ‚Üí Renault
FIA-XXXX ‚Üí Fiat
PGT-XXXX ‚Üí Peugeot
HND-XXXX ‚Üí Honda
BMW-XXXX ‚Üí BMW
MBZ-XXXX ‚Üí Mercedes-Benz
```

## ‚öôÔ∏è Tecnolog√≠as y T√©cnicas

- **LLM Base:** llama3.2 (3B)
- **Framework:** Ollama
- **T√©cnicas de ML:**
  - ‚úÖ **Few-shot learning** (principal)
  - ‚úÖ **Prompt engineering**
  - ‚úÖ **System prompts**
  - ‚úÖ **In-context learning**
- **Lenguaje:** Python 3

## üìà Resultados

| M√©todo | Precisi√≥n en Dataset | Precisi√≥n en Nuevos | Aprendizaje Real |
|--------|---------------------|---------------------|------------------|
| Modelo base | 0% | 0% | ‚ùå No |
| System prompt | 60% | 10% | ‚ö†Ô∏è Parcial |
| **Few-shot learning** | **67%** | **50%** | ‚úÖ **S√≠** |

**Conclusi√≥n:** Few-shot learning demuestra que el modelo puede aprender informaci√≥n completamente nueva con solo ver ejemplos.

## üîß Requisitos

- Ollama instalado
- Python 3.x
- Modelo llama3.2 descargado (`ollama pull llama3.2`)

## üìù Notas T√©cnicas

- **Temperature:** 0.3 (respuestas m√°s deterministas)
- **Top_p:** 0.9
- **Max tokens:** 20 (respuestas cortas)
- El modelo est√° optimizado para respuestas concisas de una sola palabra (la marca)

## üéì Proyecto Final

Este proyecto fue desarrollado para demostrar **aprendizaje real** en Large Language Models.

### Desaf√≠o planteado:
> *"¬øC√≥mo demuestro que el modelo realmente APRENDE algo nuevo y no solo usa conocimiento previo?"*

### Soluci√≥n implementada:
1. ‚úÖ Crear c√≥digos alfanum√©ricos que no existen en el mundo real
2. ‚úÖ Verificar que el modelo base NO los conoce (0% precisi√≥n)
3. ‚úÖ Aplicar few-shot learning con 20 ejemplos
4. ‚úÖ Demostrar mejora: 0% ‚Üí 67% (aprendizaje comprobado)
5. ‚úÖ Bonus: El modelo generaliza a c√≥digos nuevos (50%)

### Valor acad√©mico:
- Demuestra comprensi√≥n de in-context learning
- Aplica t√©cnicas de prompt engineering
- Mide el aprendizaje de forma cuantitativa
- Documenta experimentos con metodolog√≠a cient√≠fica
